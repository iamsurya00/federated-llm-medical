from flask import Flask, request, jsonify
from flask_cors import CORS
from dotenv import load_dotenv
import os
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from openai import OpenAI

load_dotenv()

app = Flask(__name__)
CORS(app)

# OpenRouter Client (OpenAI-compatible)
client = OpenAI(
api_key=os.getenv("OPENROUTER_API_KEY") ,
   base_url="https://openrouter.ai/api/v1"
)

# -----------------------------
# Train Local Model
# -----------------------------
def train_local_model(file):
    data = pd.read_csv(file)
    X = data[['fever','cough','fatigue','headache',
              'sore_throat','breathing_difficulty',
              'chest_pain','body_ache']]
    y = data['disease']

    model = LogisticRegression(max_iter=200)
    model.fit(X, y)
    return model

# -----------------------------
# Federated Averaging
# -----------------------------
def federated_average(models):
    avg_coef = np.mean([m.coef_ for m in models], axis=0)
    avg_intercept = np.mean([m.intercept_ for m in models], axis=0)

    global_model = models[0]
    global_model.coef_ = avg_coef
    global_model.intercept_ = avg_intercept
    return global_model

# -----------------------------
# LLM Report Generation
# -----------------------------
def generate_llm_report(name, age, gender, disease):

    prompt = f"""
    Write a short medical summary (max 120 words).
    No markdown.
    No special symbols.
    Plain text only.

    Patient: {name}, Age: {age}, Gender: {gender}
    Disease: {disease}

    Include:
    - Short clinical summary
    - 3 treatment suggestions
    - 3 precautions
    """

    completion = client.chat.completions.create(
        model="mistralai/mistral-7b-instruct",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=200
    )

    clean_text = completion.choices[0].message.content

    # Now we format professionally ourselves
    formatted_report = f"""
MEDICAL REPORT
----------------------------------------
Patient Name : {name}
Age          : {age}
Gender       : {gender}

Predicted Disease : {disease}

{clean_text}

----------------------------------------
Generated by Federated ML + LLM System
"""

    return formatted_report

# -----------------------------
# API Route
# -----------------------------
@app.route("/predict", methods=["POST"])
def predict():
    data = request.json

    name = data["name"]
    age = data["age"]
    gender = data["gender"]

    features = np.array([[
        data["fever"],
        data["cough"],
        data["fatigue"],
        data["headache"],
        data["sore_throat"],
        data["breathing_difficulty"],
        data["chest_pain"],
        data["body_ache"]
    ]])

    # Train local hospital models
    model1 = train_local_model("hospital1.csv")
    model2 = train_local_model("hospital2.csv")
    model3 = train_local_model("hospital3.csv")

    # Federated Aggregation
    global_model = federated_average([model1, model2, model3])

    # Disease Prediction
    prediction = global_model.predict(features)[0]

    # LLM Report
    report = generate_llm_report(name, age, gender, prediction)

    return jsonify({
        "disease": prediction,
        "report": report
    })

if __name__ == "__main__":
    app.run(debug=True)